{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# === Load Frozen BigBird-Pegasus Model and Tokenizer ===\n",
    "summarizer_model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "summarizer_model.eval()  # Freeze weights\n",
    "for param in summarizer_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10000</td>\n",
       "      <td>sports</td>\n",
       "      <td>soccer</td>\n",
       "      <td>Predicting Atlanta United's lineup against Col...</td>\n",
       "      <td>Only FIVE internationals allowed, count em, FI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N10001</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Mitch McConnell: DC statehood push is 'full bo...</td>\n",
       "      <td>WASHINGTON -- Senate Majority Leader Mitch McC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N10002</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Home In North Highlands Damaged By Fire</td>\n",
       "      <td>NORTH HIGHLANDS (CBS13)   Fire damaged a home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10003</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Meghan McCain blames 'liberal media' and 'thir...</td>\n",
       "      <td>Meghan McCain is speaking out after a journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10004</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Today in History: Aug 1</td>\n",
       "      <td>1714: George I becomes King Georg Ludwig, Elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113757</th>\n",
       "      <td>N123757</td>\n",
       "      <td>sports</td>\n",
       "      <td>soccer_fifa_wwc</td>\n",
       "      <td>Hope who? Alyssa Naeher's penalty save sends U...</td>\n",
       "      <td>LYON, France   At the conclusion of the United...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113758</th>\n",
       "      <td>N123758</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Chris Sale Explains What Specifically Has Gone...</td>\n",
       "      <td>The first half of Chris Sale's season could be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113759</th>\n",
       "      <td>N123759</td>\n",
       "      <td>sports</td>\n",
       "      <td>basketball_nba_videos</td>\n",
       "      <td>Raptor fans jam streets to celebrate 1st NBA t...</td>\n",
       "      <td>Canadians are celebrating the country's first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113760</th>\n",
       "      <td>N123760</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Judge won't allow Flynn to fire his attorneys</td>\n",
       "      <td>A federal judge denied the request by Michael ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113761</th>\n",
       "      <td>N123761</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Worley thinks he and Conley will rival greates...</td>\n",
       "      <td>Confidence imparts a wonderful inspiration on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113762 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        News ID Category                  Topic  \\\n",
       "0        N10000   sports                 soccer   \n",
       "1        N10001     news           newspolitics   \n",
       "2        N10002     news                 newsus   \n",
       "3        N10003     news           newspolitics   \n",
       "4        N10004     news              newsworld   \n",
       "...         ...      ...                    ...   \n",
       "113757  N123757   sports        soccer_fifa_wwc   \n",
       "113758  N123758   sports           baseball_mlb   \n",
       "113759  N123759   sports  basketball_nba_videos   \n",
       "113760  N123760     news           newspolitics   \n",
       "113761  N123761   sports           football_nfl   \n",
       "\n",
       "                                                 Headline  \\\n",
       "0       Predicting Atlanta United's lineup against Col...   \n",
       "1       Mitch McConnell: DC statehood push is 'full bo...   \n",
       "2                 Home In North Highlands Damaged By Fire   \n",
       "3       Meghan McCain blames 'liberal media' and 'thir...   \n",
       "4                                 Today in History: Aug 1   \n",
       "...                                                   ...   \n",
       "113757  Hope who? Alyssa Naeher's penalty save sends U...   \n",
       "113758  Chris Sale Explains What Specifically Has Gone...   \n",
       "113759  Raptor fans jam streets to celebrate 1st NBA t...   \n",
       "113760      Judge won't allow Flynn to fire his attorneys   \n",
       "113761  Worley thinks he and Conley will rival greates...   \n",
       "\n",
       "                                                News body  \n",
       "0       Only FIVE internationals allowed, count em, FI...  \n",
       "1       WASHINGTON -- Senate Majority Leader Mitch McC...  \n",
       "2       NORTH HIGHLANDS (CBS13)   Fire damaged a home ...  \n",
       "3       Meghan McCain is speaking out after a journali...  \n",
       "4       1714: George I becomes King Georg Ludwig, Elec...  \n",
       "...                                                   ...  \n",
       "113757  LYON, France   At the conclusion of the United...  \n",
       "113758  The first half of Chris Sale's season could be...  \n",
       "113759  Canadians are celebrating the country's first ...  \n",
       "113760  A federal judge denied the request by Michael ...  \n",
       "113761  Confidence imparts a wonderful inspiration on ...  \n",
       "\n",
       "[113762 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df=pd.read_csv(\"/teamspace/studios/this_studio/Datasets/news_min (2).tsv\", sep='\\t')\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 113762\n",
      "Example:\n",
      "NID: N10000\n",
      "Body: Only FIVE internationals allowed, count em, FIVE! So first off we should say, per our usual Atlanta United lineup predictions, this will be wrong. Why will it be wrong? Well, aside from the obvious, we still don't have a ton of data points from Frank de Boer in how he prefers to rotate his team for \n"
     ]
    }
   ],
   "source": [
    "nid2body = dict(zip(news_df[\"News ID\"], news_df[\"News body\"]))\n",
    "\n",
    "# Example check\n",
    "print(f\"Total items: {len(nid2body)}\")\n",
    "sample_nid = list(nid2body.keys())[0]\n",
    "print(f\"Example:\\nNID: {sample_nid}\\nBody: {nid2body[sample_nid][:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Only FIVE internationals allowed, count em, FIVE! So first off we should say, per our usual Atlanta United lineup predictions, this will be wrong. Why will it be wrong? Well, aside from the obvious, we still don't have a ton of data points from Frank de Boer in how he prefers to rotate his team for   let's be honest   an inferior competition. We've seen how he rotates (or doesn't rotate) in CONCACAF Champions League play, but that's a bit different because CCL was clearly a priority for the club. We got one glimpse of U.S. Open Cup rotation last week when the team played a home game as the visiting team against the Charleston Battery, but will things change on the actual road against an MLS club? Here's my predicted lineup: Let's talk about it: Kann - Seems like he's the Cup keeper. Simples. CBs - I think Leandro Gonzalez Pirez is likely to be a casualty of the 5-international player limit. Miles Robinson is still young and probably isn't in need of much rest, and as far as international players go, you probably want those to be your most indispensable and/or attacking options in case things go awry. Florentin Pogba is still a fitness concern in his ability to go 90 minutes, but considering he started the last match and then was subbed out for tactical reasons before the 90 minutes were up, I think he'll be okay. LB: This could also be Mikey Ambrose instead of Michael Parkhurst. Brek Shea will almost certainly be rested after putting in a major shift last Thursday. RB: Not a ton of other options here, and I'd think de Boer will want to see an improved performance from Escobar. Also, I think he may want to continue to pair Escobar and Pity down the right flank to allow them to continue to build a playing relationship. CM: Eric Remedi could start here for either CM. But based on Frank de Boer's stated preference on not chopping and changing between matches, I'm leaving the CMs consistent from what we saw last week. AM: Again, shooting for consistency here, but I think inserting Meram of Pereira makes sense. Pereira has struggled in his last couple outings relative to some glimpses we've seen. Pereira is also an international, and if de Boer wants to include Ezequiel Barco on the bench, he will need to shed one of his internationals from the last squad. ST: We could very well see Brandon Vazquez here, primarily down to fitness concerns. Romario Williams gutted out 120 minutes last Thursday and finished the game holding his groin, but he trained with the team fully on Monday. Vazquez came on as a sub and scored twice, but part of me thinks de Boer will want to give his backup striker as many opportunities as possible to prove his worth. With three internationals in the starting lineup, I think Eric Remedi and Ezequiel Barco will round out the five maximum allowed. What do you think? Let us know in the comments.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text = nid2body.get('N10000', \"\")\n",
    "doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your sid2text pickle file\n",
    "with open('/teamspace/studios/this_studio/Codes/mappings/sid2text.pkl', 'rb') as f:\n",
    "    sid2text = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Device and Precision Setup ===\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_dim = 192\n",
    "\n",
    "# === Utility Functions ===\n",
    "def KDE_PMI(emb1, emb2, bandwidth=0.7):\n",
    "    bandwidth = torch.tensor(bandwidth, dtype=torch.float32, device=emb1.device)\n",
    "    diff = emb1 - emb2\n",
    "    sim = torch.exp(- (diff ** 2) / (2 * bandwidth ** 2))\n",
    "    return sim\n",
    "\n",
    "def get_embedding(key, table, dim):\n",
    "    if key not in table:\n",
    "        table[key] = torch.nn.Parameter(torch.randn(dim, dtype=torch.float32, device=device) * 0.01, requires_grad=True)\n",
    "    return table[key]\n",
    "\n",
    "\n",
    "# === Load Embeddings ===\n",
    "with open(\"../../Embeddings/summary_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    summary_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "with open(\"../../Embeddings/newsbody_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    newsbody_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "with open(\"../../Embeddings/headline_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    headline_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "\n",
    "embed_tables = {\n",
    "    'summary': summary_embed,\n",
    "    'newsbody': newsbody_embed,\n",
    "    'headline': headline_embed\n",
    "}\n",
    "\n",
    "# === Load Dataset ===\n",
    "lookup_df = pd.read_csv(\"../../Datasets/Behavior_Vocab.csv\").set_index('EdgeID')\n",
    "train_df = pd.read_csv(\"../../Codes/mappings/trainfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Tail2Idx from Bhist and Bpos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting tails: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133874/133874 [02:38<00:00, 844.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail2Idx built: 173540 unique tail IDs.\n"
     ]
    }
   ],
   "source": [
    "tail_set = set()\n",
    "\n",
    "print(\"Building Tail2Idx from Bhist and Bpos...\")\n",
    "for row in tqdm(train_df.itertuples(), total=len(train_df), desc=\"Collecting tails\"):\n",
    "    try:\n",
    "        bhist = literal_eval(row.Bhist)\n",
    "        bpos = row.Bpos\n",
    "\n",
    "        # Add tails from Bhist\n",
    "        for b_id in bhist:\n",
    "            if b_id in lookup_df.index:\n",
    "                tail = lookup_df.loc[b_id, 'Tail']\n",
    "                tail_set.add(tail)\n",
    "\n",
    "        # Add tail from Bpos (in case it's not already in Bhist)\n",
    "        if bpos in lookup_df.index:\n",
    "            tail = lookup_df.loc[bpos, 'Tail']\n",
    "            tail_set.add(tail)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Skip] Error in row {row.Index}: {e}\")\n",
    "\n",
    "# === Final mappings ===\n",
    "tail_ids = sorted(tail_set)\n",
    "tail2idx = {tid: idx for idx, tid in enumerate(tail_ids)}\n",
    "idx2tail = {idx: tid for tid, idx in tail2idx.items()}\n",
    "\n",
    "print(f\"Tail2Idx built: {len(tail2idx)} unique tail IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehaviorEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_dwell = nn.Linear(1, hidden_dim, bias=False)\n",
    "        self.gamma_rel = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_e = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.f = nn.Parameter(torch.empty(1, dtype=torch.float32, device=device))\n",
    "        self.y_s = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_focus = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_acc = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, len(tail2idx))  # for tail_id classification\n",
    "        self.bpos_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W_dwell.weight, nonlinearity='linear')\n",
    "        for param in [self.gamma_rel, self.y_e, self.y_s, self.y_focus, self.y_acc]:\n",
    "            nn.init.normal_(param, mean=0.0, std=0.01)\n",
    "        with torch.no_grad():\n",
    "            self.f.copy_(torch.tensor([0.5], dtype=torch.float32, device=device))\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "        total_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "        enc_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "        pred_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "        embed_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "\n",
    "        prev_e_b = torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "\n",
    "        for t, b_id in enumerate(Bhist):\n",
    "            if b_id not in lookup_df.index:\n",
    "                continue\n",
    "\n",
    "            row = lookup_df.loc[b_id]\n",
    "            head_id, rel, tail_id = row['Head'], row['Relation'], row['Tail']\n",
    "            dwell_s = row['dwell'] / 1300.0 if pd.notna(row['dwell']) else None\n",
    "\n",
    "            head_emb = prev_e_b if t > 0 else embed_tables['headline'].get(head_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "            e_b = torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "\n",
    "            if rel in ['click', 'skip', 'gen_summ']:\n",
    "                tail_emb = embed_tables['newsbody'].get(tail_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "                if rel == 'click':\n",
    "                    dwell_v = self.W_dwell(torch.tensor([[dwell_s]], dtype=torch.float32, device=device)).squeeze(0) if dwell_s else torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "                    e_b = tail_emb + (dwell_v * self.y_e * KDE_PMI(tail_emb, head_emb))\n",
    "                elif rel == 'skip':\n",
    "                    e_b = self.f * tail_emb + (1. - self.f) * KDE_PMI(tail_emb, head_emb)\n",
    "                elif rel == 'gen_summ':\n",
    "                    hl_emb = embed_tables['headline'].get(tail_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "                    e_b = self.y_s * KDE_PMI(tail_emb, head_emb) * hl_emb\n",
    "\n",
    "            elif rel == 'summ_gen':\n",
    "                sum_emb = embed_tables['summary'].get(tail_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "                doc_emb = embed_tables['newsbody'].get(head_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "                e_b = self.y_focus * KDE_PMI(sum_emb, head_emb) + self.y_acc * KDE_PMI(sum_emb, doc_emb)\n",
    "            else:\n",
    "                tail_emb = embed_tables['newsbody'].get(tail_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "                e_b = tail_emb\n",
    "\n",
    "            e_b = self.gamma_rel * e_b\n",
    "            prev_e_b = e_b\n",
    "\n",
    "            # Current step classification loss (on tail_id)\n",
    "            if tail_id in tail2idx:\n",
    "                logits = self.classifier(e_b.unsqueeze(0))\n",
    "                target = torch.tensor([tail2idx[tail_id]], dtype=torch.long, device=device)\n",
    "                enc_loss += F.cross_entropy(logits, target)\n",
    "\n",
    "        # --- Predict e_bpos from final e_b ---\n",
    "        e_b_pos_pred = self.bpos_mlp(e_b)\n",
    "\n",
    "        # --- True e_bpos embedding ---\n",
    "        b_next = lookup_df.loc[Bpos]\n",
    "        tpos_id = b_next['Tail']\n",
    "        #e_b_pos_true = embed_tables['newsbody'].get(tpos_id, torch.zeros(hidden_dim, dtype=torch.float32, device=device))\n",
    "\n",
    "        # --- Classification loss over predicted e_bpos ---\n",
    "        logits_pos = self.classifier(e_b_pos_pred.unsqueeze(0))\n",
    "        target_pos = torch.tensor([tail2idx[tpos_id]], dtype=torch.long, device=device)\n",
    "        pred_loss = F.cross_entropy(logits_pos, target_pos)\n",
    "        \n",
    "        # --- Combine all losses ---\n",
    "        total_loss = 0.6 * enc_loss + 0.4 * pred_loss \n",
    "\n",
    "        return e_b, e_b_pos_pred, total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryInverseMapper(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, e_b_pos, e_b_hist, e_doc):\n",
    "        x = torch.cat([e_b_pos, e_b_hist, e_doc], dim=-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class CrossAttentionAdapter(nn.Module):\n",
    "    def __init__(self, query_dim, key_value_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query_proj = nn.Linear(query_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(key_value_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(key_value_dim, hidden_dim)\n",
    "        self.out_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        if query.dim() == 1: query = query.unsqueeze(0)\n",
    "        if key.dim() == 1: key = key.unsqueeze(0)\n",
    "        if value.dim() == 1: value = value.unsqueeze(0)\n",
    "\n",
    "        Q = self.query_proj(query).unsqueeze(1)  # [B, 1, H]\n",
    "        K = self.key_proj(key).unsqueeze(1)      # [B, 1, H]\n",
    "        V = self.value_proj(value).unsqueeze(1)  # [B, 1, H]\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (Q.size(-1) ** 0.5)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        attended = torch.matmul(attn_weights, V)\n",
    "        return self.out_proj(attended.squeeze(1))\n",
    "\n",
    "\n",
    "\n",
    "class B2SModel(nn.Module):\n",
    "    def __init__(self, encoder, inverse_mapper, adapter, summarizer_model, tokenizer, nid2body, sid2text):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.inverse_mapper = inverse_mapper\n",
    "        self.adapter = adapter\n",
    "        self.summarizer = summarizer_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.nid2body = nid2body\n",
    "        self.sid2text = sid2text\n",
    "        self.adapter_to_pegasus = nn.Linear(adapter.out_proj.out_features, self.summarizer.config.d_model)\n",
    "\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "        # Step 1: Encoder outputs\n",
    "        e_b, e_b_pos_pred, loss_enc = self.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "        # Step 2: Get doc embedding from head\n",
    "        head_id = lookup_df.loc[Bpos]['Head']\n",
    "        e_doc = embed_tables['newsbody'].get(head_id, torch.zeros_like(e_b))\n",
    "\n",
    "        # Step 3: Predict summary node embedding\n",
    "        e_s_pos_pred = self.inverse_mapper(e_b_pos_pred, e_b, e_doc)\n",
    "\n",
    "        # Step 4: Run summarizer (Pegasus) on doc to get generic summary\n",
    "        doc_text = self.nid2body.get(head_id, \"\")\n",
    "        inputs = self.tokenizer(doc_text, return_tensors=\"pt\", padding=True, truncation=True).to(e_b.device)\n",
    "        encoder_outputs = self.summarizer.model.encoder(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generic_ids = self.summarizer.generate(**inputs, max_new_tokens=10)\n",
    "        generic_summary = self.tokenizer.decode(generic_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Step 5: Run adapter over generic summary tokens using e_s_pos_pred\n",
    "        gen_inputs = self.tokenizer(generic_summary, return_tensors=\"pt\", truncation=True).to(e_b.device)\n",
    "        gen_input_embeds = self.summarizer.get_input_embeddings()(gen_inputs['input_ids'])  # [B, T, H]\n",
    "        pooled = gen_input_embeds.mean(dim=1)  # [B, H]\n",
    "        adapted = self.adapter(e_s_pos_pred, pooled, pooled)  # [B, H]\n",
    "\n",
    "        # Step 6: Autoregressive generation using adapted vector as context\n",
    "        generated_ids = [self.tokenizer.bos_token_id]\n",
    "        for _ in range(64):\n",
    "            prev_ids = torch.tensor(generated_ids, device=e_b.device).unsqueeze(0)  # [1, T]\n",
    "            prev_embeds = self.summarizer.get_input_embeddings()(prev_ids)  # [1, T, H]\n",
    "            attn_context = adapted.unsqueeze(1).expand(-1, prev_embeds.size(1), -1)  # [1, T, H]\n",
    "            attn_context_proj = self.adapter_to_pegasus(attn_context)  # [1, T, 1024]\n",
    "            final_input = prev_embeds + attn_context_proj  # [1, T, H]\n",
    "\n",
    "            logits = self.summarizer(\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                decoder_inputs_embeds=final_input\n",
    "            ).logits\n",
    "\n",
    "\n",
    "            next_token = torch.argmax(logits[:, -1, :], dim=-1).item()\n",
    "            generated_ids.append(next_token)\n",
    "            if next_token == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "        pred_summary = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Step 7: Supervised loss on full summary\n",
    "        sid = lookup_df.loc[Bpos]['Tail']\n",
    "        gold_summary = self.sid2text.get(sid, \"\")\n",
    "        gold_inputs = self.tokenizer(gold_summary, return_tensors=\"pt\", padding=True, truncation=True).to(e_b.device)\n",
    "        labels = gold_inputs['input_ids']\n",
    "        gold_embeds = self.summarizer.get_input_embeddings()(labels)\n",
    "        adapted_proj = self.adapter_to_pegasus(adapted)         # [1, 1024]\n",
    "        context = adapted_proj.unsqueeze(1).expand_as(gold_embeds)  # [1, 9, 1024]\n",
    "        mod_inputs = gold_embeds + context\n",
    "\n",
    "        outputs = self.summarizer(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_inputs_embeds=mod_inputs,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss_txt = outputs.loss\n",
    "\n",
    "        return (loss_enc + loss_txt, loss_txt, loss_enc), pred_summary, gold_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define Supporting Modules ===\n",
    "inverse_mapper = SummaryInverseMapper(hidden_dim).to(device)\n",
    "adapter = CrossAttentionAdapter(query_dim=192, key_value_dim=1024, hidden_dim=192).to(device)\n",
    "\n",
    "encoder = BehaviorEncoder().to(device)\n",
    "\n",
    "# === Initialize the Combined B2S Model ===\n",
    "b2s_model = B2SModel(\n",
    "    encoder=encoder,\n",
    "    inverse_mapper=inverse_mapper,\n",
    "    adapter=adapter,\n",
    "    summarizer_model=summarizer_model,\n",
    "    tokenizer=tokenizer,\n",
    "    nid2body=nid2body,\n",
    "    sid2text=sid2text\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 500 | Test samples: 50\n"
     ]
    }
   ],
   "source": [
    "train_df_subset = train_df.iloc[:550].reset_index(drop=True)\n",
    "train_rows = train_df_subset.iloc[:500]\n",
    "test_rows = train_df_subset.iloc[500:550]\n",
    "\n",
    "\n",
    "\n",
    "def extract_pairs(df, lookup_df, tail2idx):\n",
    "    data_pairs = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            Bhist = literal_eval(row['Bhist'])\n",
    "            Bpos = row['Bpos']  # explicitly given next behavior\n",
    "            if Bpos in lookup_df.index:\n",
    "                tail_id = lookup_df.loc[Bpos, 'Tail']\n",
    "                if tail_id in tail2idx:\n",
    "                    data_pairs.append((Bhist, Bpos))  # use full Bhist, and correct Bpos\n",
    "        except:\n",
    "            continue\n",
    "    return data_pairs\n",
    "\n",
    "\n",
    "train_data = extract_pairs(train_rows, lookup_df, tail2idx)\n",
    "test_data = extract_pairs(test_rows, lookup_df, tail2idx)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)} | Test samples: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running B2S Forward Pass ===\n",
      "Sample Index: 236\n",
      "Behavior History Length: 105\n",
      "Bpos: B9679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted e_b_pos shape: torch.Size([192])\n",
      "True Tail ID (Bpos): S-238\n",
      "\n",
      "--- Personalized Summary Output ---\n",
      "Gold Summary   : The guard, a 19-year-old, told a Los Angeles television station he didn't want to press charges against Elliott\n",
      "Predicted      : a : a , a [ 2020 option for [ a] , who wrote : the article [ a for a ] was reported that last game of the @xmath0-s who wrote : a last played for the article [ ] wrote : one of the players who had been selected\n",
      "\n",
      "--- Loss Breakdown ---\n",
      "Total Loss     : 775.4350\n",
      "Gen Loss       : 10.2907\n",
      "Encoder Loss   : 765.1443\n"
     ]
    }
   ],
   "source": [
    "# === Pick one sample ===\n",
    "sample_idx = random.randint(0, len(train_data) - 1)\n",
    "Bhist, Bpos = train_data[sample_idx]\n",
    "\n",
    "print(f\"\\n=== Running B2S Forward Pass ===\")\n",
    "print(f\"Sample Index: {sample_idx}\")\n",
    "print(f\"Behavior History Length: {len(Bhist)}\")\n",
    "print(f\"Bpos: {Bpos}\")\n",
    "\n",
    "b2s_model.eval()\n",
    "with torch.no_grad():\n",
    "    e_b, e_b_pos_pred, _ = b2s_model.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "    head_id = lookup_df.loc[Bpos]['Head']\n",
    "    e_doc = embed_tables['newsbody'].get(head_id, torch.zeros_like(e_b))\n",
    "\n",
    "    e_s_pos_pred = b2s_model.inverse_mapper(e_b_pos_pred, e_b, e_doc)\n",
    "\n",
    "    # Run model to get detailed losses\n",
    "    (loss_total, loss_gen, loss_enc), pred_summary, gold_summary = b2s_model(\n",
    "        Bhist, Bpos, lookup_df, tail2idx, embed_tables\n",
    "    )\n",
    "\n",
    "# === Metadata ===\n",
    "true_tail_id = lookup_df.loc[Bpos]['Tail']\n",
    "print(f\"\\nPredicted e_b_pos shape: {e_b_pos_pred.shape}\")\n",
    "print(f\"True Tail ID (Bpos): {true_tail_id}\")\n",
    "\n",
    "# === Summaries ===\n",
    "print(\"\\n--- Personalized Summary Output ---\")\n",
    "print(f\"Gold Summary   : {gold_summary}\")\n",
    "print(f\"Predicted      : {pred_summary}\")\n",
    "\n",
    "# === Losses ===\n",
    "print(\"\\n--- Loss Breakdown ---\")\n",
    "print(f\"Total Loss     : {loss_total:.4f}\")\n",
    "print(f\"Gen Loss       : {loss_gen:.4f}\")\n",
    "print(f\"Encoder Loss   : {loss_enc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¦ Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [33:13<00:00,  3.99s/it, Loss=155.3428, GenLoss=7.0525]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 1] Avg Loss: 567.8814 | Gen Loss: 8.8865\n",
      "\n",
      "ðŸŸ¦ Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [43:17<00:00,  5.20s/it, Loss=149.0499, GenLoss=6.6194]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 2] Avg Loss: 545.5701 | Gen Loss: 8.0504\n",
      "\n",
      "ðŸŸ¦ Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [43:51<00:00,  5.26s/it, Loss=139.4202, GenLoss=5.9603]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 3] Avg Loss: 501.2206 | Gen Loss: 7.4807\n",
      "\n",
      "ðŸŸ¦ Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [44:13<00:00,  5.31s/it, Loss=129.9762, GenLoss=5.4588]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 4] Avg Loss: 465.0706 | Gen Loss: 7.0277\n",
      "\n",
      "ðŸŸ¦ Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [43:16<00:00,  5.19s/it, Loss=122.6427, GenLoss=5.1154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 5] Avg Loss: 438.0654 | Gen Loss: 6.6860\n",
      "\n",
      "ðŸŸ¦ Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [38:56<00:00,  4.67s/it, Loss=117.5574, GenLoss=3.8597] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 6] Avg Loss: 420.5090 | Gen Loss: 6.2473\n",
      "\n",
      "ðŸŸ¦ Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [37:31<00:00,  4.50s/it, Loss=115.2644, GenLoss=3.9074] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 7] Avg Loss: 410.3392 | Gen Loss: 5.6972\n",
      "\n",
      "ðŸŸ¦ Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [36:41<00:00,  4.40s/it, Loss=112.8757, GenLoss=3.0891] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 8] Avg Loss: 403.7120 | Gen Loss: 5.2266\n",
      "\n",
      "ðŸŸ¦ Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [38:51<00:00,  4.66s/it, Loss=112.3568, GenLoss=3.6583] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 9] Avg Loss: 398.9620 | Gen Loss: 4.9982\n",
      "\n",
      "ðŸŸ¦ Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [39:31<00:00,  4.74s/it, Loss=110.7968, GenLoss=2.8649] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 10] Avg Loss: 395.1373 | Gen Loss: 4.8328\n",
      "\n",
      "ðŸŸ¦ Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [39:26<00:00,  4.73s/it, Loss=110.2049, GenLoss=2.8353] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 11] Avg Loss: 391.9202 | Gen Loss: 4.7717\n",
      "\n",
      "ðŸŸ¦ Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [39:08<00:00,  4.70s/it, Loss=110.0589, GenLoss=3.1343] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 12] Avg Loss: 388.9336 | Gen Loss: 4.6155\n",
      "\n",
      "ðŸŸ¦ Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [40:44<00:00,  4.89s/it, Loss=109.0201, GenLoss=2.4819] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 13] Avg Loss: 386.2540 | Gen Loss: 4.5298\n",
      "\n",
      "ðŸŸ¦ Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [40:52<00:00,  4.90s/it, Loss=108.4744, GenLoss=2.2995] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 14] Avg Loss: 383.8017 | Gen Loss: 4.4792\n",
      "\n",
      "ðŸŸ¦ Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [40:22<00:00,  4.84s/it, Loss=108.2545, GenLoss=2.4383] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 15] Avg Loss: 381.5207 | Gen Loss: 4.4312\n",
      "\n",
      "ðŸŸ¦ Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [39:23<00:00,  4.73s/it, Loss=107.7720, GenLoss=2.3173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 16] Avg Loss: 379.4210 | Gen Loss: 4.4106\n",
      "\n",
      "ðŸŸ¦ Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [40:06<00:00,  4.81s/it, Loss=107.0946, GenLoss=2.0061] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Epoch 17] Avg Loss: 377.4765 | Gen Loss: 4.4043\n",
      "\n",
      "ðŸŸ¦ Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 267/500 [20:45<20:02,  5.16s/it, Loss=410.4525, GenLoss=2.3604] "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(b2s_model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "save_every = 20\n",
    "checkpoint_template = \"b2s_model_epoch{:03d}.pt\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    b2s_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_gen_loss = 0.0\n",
    "\n",
    "    print(f\"\\nðŸŸ¦ Epoch {epoch+1}/{num_epochs}\")\n",
    "    pbar = tqdm(train_data, desc=f\"Training Epoch {epoch+1}\", dynamic_ncols=True)\n",
    "\n",
    "    for Bhist, Bpos in pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            (loss_total, loss_txt, loss_enc), pred_summary, gold_summary = b2s_model(\n",
    "                Bhist, Bpos, lookup_df, tail2idx, embed_tables\n",
    "            )\n",
    "        except Exception as e:\n",
    "            pbar.set_postfix_str(f\"[Skip {Bpos}] {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_total.item()\n",
    "        total_gen_loss += loss_txt.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss_total.item():.4f}\",\n",
    "            \"GenLoss\": f\"{loss_txt.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    avg_gen_loss = total_gen_loss / len(train_data)\n",
    "    print(f\"âœ… [Epoch {epoch+1}] Avg Loss: {avg_loss:.4f} | Gen Loss: {avg_gen_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % save_every == 0:\n",
    "        ckpt_path = checkpoint_template.format(epoch + 1)\n",
    "        torch.save(b2s_model.state_dict(), ckpt_path)\n",
    "        print(f\"ðŸ“Œ Saved checkpoint: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Re-initialize your model architecture (same as training) ===\n",
    "encoder = BehaviorEncoder().to(device)\n",
    "inverse_mapper = SummaryInverseMapper(hidden_dim).to(device)\n",
    "adapter = CrossAttentionAdapter(query_dim=192, key_value_dim=1024, hidden_dim=192).to(device)\n",
    "\n",
    "b2s_model = B2SModel(\n",
    "    encoder=encoder,\n",
    "    inverse_mapper=inverse_mapper,\n",
    "    adapter=adapter,\n",
    "    summarizer_model=summarizer_model,\n",
    "    tokenizer=tokenizer,\n",
    "    nid2body=nid2body,\n",
    "    sid2text=sid2text\n",
    ").to(device)\n",
    "\n",
    "# === Load weights ===\n",
    "checkpoint_path = \"b2s_model_epoch100.pt\"  # <-- change as needed\n",
    "b2s_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "print(f\"âœ… Loaded model checkpoint: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "b2s_model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for Bhist, Bpos in tqdm(test_data, desc=\"ðŸ” Evaluating\"):\n",
    "        try:\n",
    "            loss, pred_summary, gold_summary = b2s_model(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "            true_tail = lookup_df.loc[Bpos, 'Tail']\n",
    "        except Exception as e:\n",
    "            print(f\"[Skip] {Bpos}: {e}\")\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            'Bpos': Bpos,\n",
    "            'true_tail_id': true_tail,\n",
    "            'pred_summary': pred_summary,\n",
    "            'gold_summary': gold_summary\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"b2s_eval_results.csv\", index=False)\n",
    "print(\"âœ… Results saved to: b2s_eval_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
