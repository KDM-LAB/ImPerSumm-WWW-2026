# ImPerSum
Information Modulated Personalized Summarizer

ğŸ“˜ **BEHAVIOR EXTRACTION & TRAINING INSTANCE GENERATION**

ğŸ“¥ INPUT
CSV file with user interaction sequences.

Required columns:

â€¢ UserID   â†’ unique user identifier  
â€¢ Docs     â†’ stringified Python list of document IDs  
â€¢ Action   â†’ stringified Python list of actions (aligned with Docs)

Example:

UserID,Docs,Action  

U1,"['N1','N2']","['click','summ_gen']"

âš™ï¸ PROCESSING LOGIC

â‘  BEHAVIOR GRAPH CONSTRUCTION

â€¢ Each interaction is assigned a unique EdgeID (B1, B2, â€¦)

â€¢ First interaction:
    
    User â”€â”€(action)â”€â”€â–¶ Docâ‚€

â€¢ Subsequent interactions:

    Docáµ¢â‚‹â‚ â”€â”€(action)â”€â”€â–¶ Docáµ¢

â‘¡ BEHAVIOR LOOKUP TABLE

â€¢ Columns:

  EdgeID | Head | Relation | Tail | User

â€¢ Relations:
  
  { click, skip, gen_summ, summ_gen }

â‘¢ DWELL TIME AUGMENTATION

â€¢ click      â†’ pens dataset dwell âˆˆ [20, 1230]
â€¢ otherwise  â†’ NaN

â‘£ TRAINING INSTANCE EXTRACTION

â€¢ For every `summ_gen` event:
  Bhist = all EdgeIDs before this event
  Bpos  = EdgeID of the current summ_gen

â€¢ One training instance per summ_gen

ğŸ“¤ OUTPUT

â‘  Behavior Vocabulary (Behavior_Vocab.csv)

â€¢ Global behavior graph

â€¢ One row per interaction edge

â‘¡ Training Dataset (train_df)

â€¢ Columns:
  UserID | Bhist | Bpos

â€¢ Supervision format:
  Bhist â”€â”€â–¶ Bpos

ğŸ” VALIDATION

All Bpos values are verified to exist in the behavior lookup table.

ğŸ§© USE CASES

â€¢ Sequential recommendation  
â€¢ Next-behavior prediction  
â€¢ Behavior-to-Summary (B2S) modeling  
â€¢ User behavior graph learning

ğŸ“¦ DEPENDENCIES
pip install pandas numpy tqdm

â–¶ RUN

Update CSV path and execute:
behavior_exptraction.ipynb notebook


ğŸ“˜ **CORPUS TO EMBEDDING CONVERSION**

ğŸ”¹ This script generates dense semantic embeddings for news headlines, news bodies, and summaries using the **E5 (intfloat/e5-base-v2)** transformer model with GPU support.

ğŸ”¹ Texts are batch-encoded, mean-pooled, L2-normalized, and stored as **NewsID â†’ embedding** mappings in pickle files for efficient downstream retrieval.

ğŸ”¹ The resulting embeddings are used as fixed representations in personalization, retrieval, and behavior-to-summary modeling pipelines.

â–¶ RUN

Update pkl path and execute:
embedding_generation.ipynb notebook
