{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a96b6cd5a143758c8ac7ee5e6715dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e31f3ff4314c6693493ed3ec0e29a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb9544d6cf2463c82d379431a6c73e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563a9609a64d42e7b9d679659e9d34ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3aa4006e0f848c9953813d2e1252463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "summarizer_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "summarizer_model.eval()\n",
    "for param in summarizer_model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10000</td>\n",
       "      <td>sports</td>\n",
       "      <td>soccer</td>\n",
       "      <td>Predicting Atlanta United's lineup against Col...</td>\n",
       "      <td>Only FIVE internationals allowed, count em, FI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N10001</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Mitch McConnell: DC statehood push is 'full bo...</td>\n",
       "      <td>WASHINGTON -- Senate Majority Leader Mitch McC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N10002</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Home In North Highlands Damaged By Fire</td>\n",
       "      <td>NORTH HIGHLANDS (CBS13)   Fire damaged a home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10003</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Meghan McCain blames 'liberal media' and 'thir...</td>\n",
       "      <td>Meghan McCain is speaking out after a journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10004</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Today in History: Aug 1</td>\n",
       "      <td>1714: George I becomes King Georg Ludwig, Elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113757</th>\n",
       "      <td>N123757</td>\n",
       "      <td>sports</td>\n",
       "      <td>soccer_fifa_wwc</td>\n",
       "      <td>Hope who? Alyssa Naeher's penalty save sends U...</td>\n",
       "      <td>LYON, France   At the conclusion of the United...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113758</th>\n",
       "      <td>N123758</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball_mlb</td>\n",
       "      <td>Chris Sale Explains What Specifically Has Gone...</td>\n",
       "      <td>The first half of Chris Sale's season could be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113759</th>\n",
       "      <td>N123759</td>\n",
       "      <td>sports</td>\n",
       "      <td>basketball_nba_videos</td>\n",
       "      <td>Raptor fans jam streets to celebrate 1st NBA t...</td>\n",
       "      <td>Canadians are celebrating the country's first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113760</th>\n",
       "      <td>N123760</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Judge won't allow Flynn to fire his attorneys</td>\n",
       "      <td>A federal judge denied the request by Michael ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113761</th>\n",
       "      <td>N123761</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Worley thinks he and Conley will rival greates...</td>\n",
       "      <td>Confidence imparts a wonderful inspiration on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113762 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        News ID Category                  Topic  \\\n",
       "0        N10000   sports                 soccer   \n",
       "1        N10001     news           newspolitics   \n",
       "2        N10002     news                 newsus   \n",
       "3        N10003     news           newspolitics   \n",
       "4        N10004     news              newsworld   \n",
       "...         ...      ...                    ...   \n",
       "113757  N123757   sports        soccer_fifa_wwc   \n",
       "113758  N123758   sports           baseball_mlb   \n",
       "113759  N123759   sports  basketball_nba_videos   \n",
       "113760  N123760     news           newspolitics   \n",
       "113761  N123761   sports           football_nfl   \n",
       "\n",
       "                                                 Headline  \\\n",
       "0       Predicting Atlanta United's lineup against Col...   \n",
       "1       Mitch McConnell: DC statehood push is 'full bo...   \n",
       "2                 Home In North Highlands Damaged By Fire   \n",
       "3       Meghan McCain blames 'liberal media' and 'thir...   \n",
       "4                                 Today in History: Aug 1   \n",
       "...                                                   ...   \n",
       "113757  Hope who? Alyssa Naeher's penalty save sends U...   \n",
       "113758  Chris Sale Explains What Specifically Has Gone...   \n",
       "113759  Raptor fans jam streets to celebrate 1st NBA t...   \n",
       "113760      Judge won't allow Flynn to fire his attorneys   \n",
       "113761  Worley thinks he and Conley will rival greates...   \n",
       "\n",
       "                                                News body  \n",
       "0       Only FIVE internationals allowed, count em, FI...  \n",
       "1       WASHINGTON -- Senate Majority Leader Mitch McC...  \n",
       "2       NORTH HIGHLANDS (CBS13)   Fire damaged a home ...  \n",
       "3       Meghan McCain is speaking out after a journali...  \n",
       "4       1714: George I becomes King Georg Ludwig, Elec...  \n",
       "...                                                   ...  \n",
       "113757  LYON, France   At the conclusion of the United...  \n",
       "113758  The first half of Chris Sale's season could be...  \n",
       "113759  Canadians are celebrating the country's first ...  \n",
       "113760  A federal judge denied the request by Michael ...  \n",
       "113761  Confidence imparts a wonderful inspiration on ...  \n",
       "\n",
       "[113762 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df=pd.read_csv(\"/teamspace/studios/this_studio/Data/news_min (2).tsv\", sep='\\t')\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 113762\n",
      "Example:\n",
      "NID: N10000\n",
      "Body: Predicting Atlanta United's lineup against Columbus Crew in the U.S. Open Cup\n"
     ]
    }
   ],
   "source": [
    "nid2body = dict(zip(news_df[\"News ID\"], news_df[\"Headline\"]))\n",
    "\n",
    "# Example check\n",
    "print(f\"Total items: {len(nid2body)}\")\n",
    "sample_nid = list(nid2body.keys())[0]\n",
    "print(f\"Example:\\nNID: {sample_nid}\\nBody: {nid2body[sample_nid][:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your sid2text pickle file\n",
    "with open('/teamspace/studios/this_studio/Data/sid2text.pkl', 'rb') as f:\n",
    "    sid2text = pickle.load(f)\n",
    "len(sid2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Device and Precision Setup ===\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_dim = 192\n",
    "\n",
    "# === Utility Functions ===\n",
    "def KDE_PMI(emb1, emb2, bandwidth=0.7):\n",
    "    bandwidth = torch.tensor(bandwidth, dtype=torch.float32, device=emb1.device)\n",
    "    diff = emb1 - emb2\n",
    "    sim = torch.exp(- (diff ** 2) / (2 * bandwidth ** 2))\n",
    "    return sim\n",
    "\n",
    "def get_embedding(key, table, dim):\n",
    "    if key not in table:\n",
    "        table[key] = torch.nn.Parameter(torch.randn(dim, dtype=torch.float32, device=device) * 0.01, requires_grad=True)\n",
    "    return table[key]\n",
    "\n",
    "\n",
    "# === Load Embeddings ===\n",
    "with open(\"/teamspace/studios/this_studio/Data/summary_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    summary_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "with open(\"/teamspace/studios/this_studio/Data/newsbody_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    newsbody_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "with open(\"/teamspace/studios/this_studio/Data/headline_embeddings_pca192.pkl\", \"rb\") as f:\n",
    "    headline_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k, v in pickle.load(f).items()}\n",
    "\n",
    "embed_tables = {\n",
    "    'summary': summary_embed,\n",
    "    'newsbody': newsbody_embed,\n",
    "    'headline': headline_embed\n",
    "}\n",
    "\n",
    "# === Load Dataset ===\n",
    "lookup_df = pd.read_csv(\"/teamspace/studios/this_studio/Data/Behavior_Vocab.csv\").set_index('EdgeID')\n",
    "train_df = pd.read_csv(\"/teamspace/studios/this_studio/Data/trainfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Tail2Idx from Bhist and Bpos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting tails: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133874/133874 [01:25<00:00, 1565.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail2Idx built: 173540 unique tail IDs.\n"
     ]
    }
   ],
   "source": [
    "tail_set = set()\n",
    "\n",
    "print(\"Building Tail2Idx from Bhist and Bpos...\")\n",
    "for row in tqdm(train_df.itertuples(), total=len(train_df), desc=\"Collecting tails\"):\n",
    "    try:\n",
    "        bhist = literal_eval(row.Bhist)\n",
    "        bpos = row.Bpos\n",
    "\n",
    "        # Add tails from Bhist\n",
    "        for b_id in bhist:\n",
    "            if b_id in lookup_df.index:\n",
    "                tail = lookup_df.loc[b_id, 'Tail']\n",
    "                tail_set.add(tail)\n",
    "\n",
    "        # Add tail from Bpos (in case it's not already in Bhist)\n",
    "        if bpos in lookup_df.index:\n",
    "            tail = lookup_df.loc[bpos, 'Tail']\n",
    "            tail_set.add(tail)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Skip] Error in row {row.Index}: {e}\")\n",
    "\n",
    "# === Final mappings ===\n",
    "tail_ids = sorted(tail_set)\n",
    "tail2idx = {tid: idx for idx, tid in enumerate(tail_ids)}\n",
    "idx2tail = {idx: tid for tid, idx in tail2idx.items()}\n",
    "\n",
    "print(f\"Tail2Idx built: {len(tail2idx)} unique tail IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehaviorEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_dwell = nn.Linear(1, hidden_dim, bias=False)\n",
    "        self.gamma_rel = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_e = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.f = nn.Parameter(torch.empty(1, dtype=torch.float32, device=device))\n",
    "        self.y_s = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_focus = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.y_acc = nn.Parameter(torch.empty(hidden_dim, dtype=torch.float32, device=device))\n",
    "        self.K_short = nn.Parameter(torch.randn(30, dtype=torch.float32, device=device))  # last 50 steps\n",
    "        self.K_long  = nn.Parameter(torch.randn(10, dtype=torch.float32, device=device))\n",
    "        self.K_event = nn.Parameter(torch.randn(30, dtype=torch.float32, device=device))\n",
    "\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, len(tail2idx))  # for tail_id classification\n",
    "        self.bpos_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W_dwell.weight, nonlinearity='linear')\n",
    "        for param in [self.gamma_rel, self.y_e, self.y_s, self.y_focus, self.y_acc]:\n",
    "            nn.init.normal_(param, mean=0.0, std=0.01)\n",
    "        with torch.no_grad():\n",
    "            self.f.copy_(torch.tensor([0.5], dtype=torch.float32, device=device))\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "        total_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "        enc_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "        pred_loss = torch.tensor(0., dtype=torch.float32, device=device)\n",
    "\n",
    "        prev_e_b = torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "        memory = []\n",
    "\n",
    "        for t, b_id in enumerate(Bhist):\n",
    "            if b_id not in lookup_df.index:\n",
    "                continue\n",
    "\n",
    "            row = lookup_df.loc[b_id]\n",
    "            head_id, rel, tail_id = row['Head'], row['Relation'], row['Tail']\n",
    "            dwell_s = row['dwell'] / 130000.0 if pd.notna(row['dwell']) else None\n",
    "\n",
    "            head_emb = prev_e_b if t > 0 else embed_tables['headline'].get(head_id, torch.zeros(hidden_dim, device=device))\n",
    "            e_b = torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "            mem_e_b = torch.zeros(hidden_dim, dtype=torch.float32, device=device)\n",
    "            \n",
    "\n",
    "            if rel in ['click', 'skip', 'gen_summ']:\n",
    "                tail_emb = embed_tables['newsbody'].get(tail_id, torch.zeros(hidden_dim, device=device))\n",
    "                if rel == 'click':\n",
    "                    dwell_v = self.W_dwell(torch.tensor([[dwell_s]], dtype=torch.float32, device=device)).squeeze(0) if dwell_s else torch.zeros(hidden_dim, device=device)\n",
    "                    e_b = tail_emb + (dwell_v * self.y_e * KDE_PMI(tail_emb, head_emb))\n",
    "                elif rel == 'skip':\n",
    "                    e_b = self.f * tail_emb + (1. - self.f) * KDE_PMI(tail_emb, head_emb)\n",
    "                elif rel == 'gen_summ':\n",
    "                    hl_emb = embed_tables['headline'].get(tail_id, torch.zeros(hidden_dim, device=device))\n",
    "                    e_b = self.y_s * KDE_PMI(tail_emb, head_emb) * hl_emb\n",
    "\n",
    "            elif rel == 'summ_gen':\n",
    "                sum_emb = embed_tables['summary'].get(tail_id, torch.zeros(hidden_dim, device=device))\n",
    "                doc_emb = embed_tables['newsbody'].get(head_id, torch.zeros(hidden_dim, device=device))\n",
    "                e_b = self.y_focus * KDE_PMI(sum_emb, head_emb) + self.y_acc * KDE_PMI(sum_emb, doc_emb)\n",
    "            else:\n",
    "                tail_emb = embed_tables['newsbody'].get(tail_id, torch.zeros(hidden_dim, device=device))\n",
    "                e_b = tail_emb\n",
    "\n",
    "            # Apply Î³ to e_b\n",
    "            e_b = self.gamma_rel * e_b\n",
    "            e_b_orig = e_b.clone()\n",
    "            # --- MEMORY INJECTION ---\n",
    "            if memory:\n",
    "                idxs = torch.arange(len(memory)-1, -1, -1, device=device)\n",
    "                memory_stack = torch.stack(memory)\n",
    "\n",
    "                w_short = self.K_short[idxs.clamp(max=len(self.K_short)-1)]\n",
    "                w_long  = self.K_long [idxs.clamp(max=len(self.K_long )-1)]\n",
    "                w_event = self.K_event[idxs.clamp(max=len(self.K_event)-1)]\n",
    "\n",
    "                m_short = (w_short.unsqueeze(1) * memory_stack).sum(0)\n",
    "                m_long  = (w_long .unsqueeze(1) * memory_stack).sum(0)\n",
    "                m_event = (w_event.unsqueeze(1) * memory_stack).sum(0)\n",
    "\n",
    "                gates = torch.softmax(torch.stack([m_short, m_long, m_event]), dim=0)\n",
    "                mem_e_b = gates[0]*m_short + gates[1]*m_long + gates[2]*m_event\n",
    "\n",
    "            memory.append(mem_e_b.detach())  # Detach to stop gradient\n",
    "            e_b = e_b_orig + mem_e_b\n",
    "            prev_e_b = e_b\n",
    "\n",
    "            # BCE or CE loss over current tail_id\n",
    "            if tail_id in tail2idx:\n",
    "                logits = self.classifier(e_b.unsqueeze(0))\n",
    "                target = torch.tensor([tail2idx[tail_id]], dtype=torch.long, device=device)\n",
    "                enc_loss += F.cross_entropy(logits, target)\n",
    "\n",
    "        # === Final Step Prediction ===\n",
    "        e_b_pos_pred = self.bpos_mlp(e_b)\n",
    "        b_next = lookup_df.loc[Bpos]\n",
    "        tpos_id = b_next['Tail']\n",
    "        logits_pos = self.classifier(e_b_pos_pred.unsqueeze(0))\n",
    "        target_pos = torch.tensor([tail2idx[tpos_id]], dtype=torch.long, device=device)\n",
    "        pred_loss = F.cross_entropy(logits_pos, target_pos)\n",
    "\n",
    "        total_loss = (0.5 * enc_loss + 0.5 * pred_loss)/(100*len(Bhist)+1)\n",
    "        return e_b, e_b_pos_pred, total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SummaryInverseMapper(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, e_b_pos, e_b_hist, e_doc):\n",
    "        x = torch.cat([e_b_pos, e_b_hist, e_doc], dim=-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class CrossAttentionAdapter(nn.Module):\n",
    "    def __init__(self, query_dim, key_value_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query_proj = nn.Linear(query_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(key_value_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(key_value_dim, hidden_dim)\n",
    "        self.out_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        if query.dim() == 1: query = query.unsqueeze(0)\n",
    "        if key.dim() == 1: key = key.unsqueeze(0)\n",
    "        if value.dim() == 1: value = value.unsqueeze(0)\n",
    "\n",
    "        Q = self.query_proj(query).unsqueeze(1)  # [B, 1, H]\n",
    "        K = self.key_proj(key).unsqueeze(1)      # [B, 1, H]\n",
    "        V = self.value_proj(value).unsqueeze(1)  # [B, 1, H]\n",
    "\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (Q.size(-1) ** 0.5)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        attended = torch.matmul(attn_weights, V)\n",
    "        return self.out_proj(attended.squeeze(1))\n",
    "\n",
    "\n",
    "class B2SModel(nn.Module):\n",
    "    def __init__(self, encoder, inverse_mapper, adapter, summarizer_model, tokenizer, nid2body, sid2text):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.inverse_mapper = inverse_mapper\n",
    "        self.adapter = adapter\n",
    "        self.summarizer = summarizer_model  # T5ForConditionalGeneration\n",
    "        self.tokenizer = tokenizer\n",
    "        self.nid2body = nid2body\n",
    "        self.sid2text = sid2text\n",
    "        self.adapter_to_t5 = nn.Linear(adapter.out_proj.out_features, summarizer_model.config.d_model)\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # Step 1: Encode user behavior\n",
    "        e_b, e_b_pos_pred, loss_enc = self.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "        # Step 2: Get document embedding and text\n",
    "        head_id = lookup_df.loc[Bpos]['Head']\n",
    "        tail_id = lookup_df.loc[Bpos]['Tail']\n",
    "        e_doc = embed_tables['newsbody'].get(head_id, torch.zeros_like(e_b))\n",
    "        doc_text = self.nid2body.get(head_id, \"\")\n",
    "\n",
    "        # Step 3: Predict personalized summary embedding\n",
    "        e_s_pos_pred = self.inverse_mapper(e_b_pos_pred, e_b, e_doc)\n",
    "        adapted = self.adapter(e_s_pos_pred, e_doc, e_b)\n",
    "        adapted_proj = self.adapter_to_t5(adapted)  # [1, d_model]\n",
    "\n",
    "        # Step 4: Encode document text with T5\n",
    "        input_enc = self.tokenizer(doc_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        encoder_outputs = self.summarizer.encoder(\n",
    "            input_ids=input_enc['input_ids'],\n",
    "            attention_mask=input_enc['attention_mask'],\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        # Step 5: Prepare teacher-forced decoder inputs\n",
    "        sid = lookup_df.loc[Bpos]['Tail']\n",
    "        gold_summary = self.sid2text.get(sid, \"\")\n",
    "        gold_inputs = self.tokenizer(gold_summary, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        decoder_input_ids = gold_inputs['input_ids'][:, :-1].contiguous()\n",
    "        decoder_labels = gold_inputs['input_ids'][:, 1:].contiguous()\n",
    "\n",
    "        # Step 6: Inject adapter vector as first token\n",
    "        adapter_token_embed = adapted_proj.unsqueeze(1)  # [1, 1, d_model]\n",
    "        dec_embed = self.summarizer.get_input_embeddings()(decoder_input_ids)  # [1, T, d_model]\n",
    "        final_embed = torch.cat([adapter_token_embed, dec_embed], dim=1)\n",
    "\n",
    "        decoder_labels = torch.cat([\n",
    "            torch.full((1, 1), -100, dtype=torch.long, device=device),  # mask adapter loss\n",
    "            decoder_labels\n",
    "        ], dim=1)\n",
    "\n",
    "        # Step 7: Decode with adapter-injected embeddings\n",
    "        outputs = self.summarizer(\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            decoder_inputs_embeds=final_embed,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        loss_txt = outputs.loss\n",
    "\n",
    "        # Step 8: Decode predicted summary\n",
    "        pred_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "        pred_summary = self.tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Step 9: Return losses and summaries\n",
    "        impersum_loss = 0.5 * loss_enc + 0.5 * loss_txt\n",
    "        return (impersum_loss, loss_txt, loss_enc), pred_summary, gold_summary, doc_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define Supporting Modules ===\n",
    "inverse_mapper = SummaryInverseMapper(hidden_dim).to(device)\n",
    "adapter = CrossAttentionAdapter(query_dim=192, key_value_dim=192, hidden_dim=192).to(device)\n",
    "\n",
    "encoder = BehaviorEncoder().to(device)\n",
    "\n",
    "# === Initialize the Combined B2S Model ===\n",
    "b2s_model = B2SModel(\n",
    "    encoder=encoder,\n",
    "    inverse_mapper=inverse_mapper,\n",
    "    adapter=adapter,\n",
    "    summarizer_model=summarizer_model,\n",
    "    tokenizer=tokenizer,\n",
    "    nid2body=nid2body,\n",
    "    sid2text=sid2text\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 500 | Test samples: 50\n"
     ]
    }
   ],
   "source": [
    "train_df_subset = train_df.iloc[:550].reset_index(drop=True)\n",
    "train_rows = train_df_subset.iloc[:500]\n",
    "test_rows = train_df_subset.iloc[500:550]\n",
    "\n",
    "\n",
    "\n",
    "def extract_pairs(df, lookup_df, tail2idx):\n",
    "    data_pairs = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            Bhist = literal_eval(row['Bhist'])\n",
    "            Bpos = row['Bpos']  # explicitly given next behavior\n",
    "            if Bpos in lookup_df.index:\n",
    "                tail_id = lookup_df.loc[Bpos, 'Tail']\n",
    "                if tail_id in tail2idx:\n",
    "                    data_pairs.append((Bhist, Bpos))  # use full Bhist, and correct Bpos\n",
    "        except:\n",
    "            continue\n",
    "    return data_pairs\n",
    "\n",
    "\n",
    "train_data = extract_pairs(train_rows, lookup_df, tail2idx)\n",
    "test_data = extract_pairs(test_rows, lookup_df, tail2idx)\n",
    "\n",
    "print(f\"Train samples: {len(train_data)} | Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running B2S Forward Pass ===\n",
      "Sample Index: 127\n",
      "Behavior History Length: 133\n",
      "Bpos: B5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted e_b_pos shape: torch.Size([192])\n",
      "True Tail ID (Bpos): S-128\n",
      "\n",
      "--- Personalized Summary Output ---\n",
      "Generic Summary   : AGUAS VERDES, Peru (AP)   Tired and thirsty, Betania RamÃ­rez crossed into Peru on Friday with her 1-year-old girl in her arms and her 8-year-old boy beside her.\n",
      "Gold Summary   : AGUAS VERDES, Peru (AP)   Tired and thirsty, Betania RamÃ­rez crossed into Peru on Friday with her 1-year-old girl in her arms and her 8-year-old boy beside her.\n",
      "Predicted      : ))  ERS    )) ,,,)) however ,,s,,,,,,,, und----,-, --year-- ,\n",
      "\n",
      "--- Loss Breakdown ---\n",
      "Total Loss     : 5.0444\n",
      "Gen Loss       : 10.0281\n",
      "Encoder Loss   : 0.0608\n"
     ]
    }
   ],
   "source": [
    "# === Pick one sample ===\n",
    "sample_idx = random.randint(0, len(train_data) - 1)\n",
    "Bhist, Bpos = train_data[sample_idx]\n",
    "\n",
    "print(f\"\\n=== Running B2S Forward Pass ===\")\n",
    "print(f\"Sample Index: {sample_idx}\")\n",
    "print(f\"Behavior History Length: {len(Bhist)}\")\n",
    "print(f\"Bpos: {Bpos}\")\n",
    "\n",
    "b2s_model.eval()\n",
    "with torch.no_grad():\n",
    "    e_b, e_b_pos_pred, _ = b2s_model.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "    head_id = lookup_df.loc[Bpos]['Head']\n",
    "    e_doc = embed_tables['newsbody'].get(head_id, torch.zeros_like(e_b))\n",
    "\n",
    "    e_s_pos_pred = b2s_model.inverse_mapper(e_b_pos_pred, e_b, e_doc)\n",
    "\n",
    "    # Run model to get detailed losses\n",
    "    (loss_total, loss_gen, loss_enc), pred_summary, gold_summary, generic_summary = b2s_model(\n",
    "        Bhist, Bpos, lookup_df, tail2idx, embed_tables\n",
    "    )\n",
    "\n",
    "# === Metadata ===\n",
    "true_tail_id = lookup_df.loc[Bpos]['Tail']\n",
    "print(f\"\\nPredicted e_b_pos shape: {e_b_pos_pred.shape}\")\n",
    "print(f\"True Tail ID (Bpos): {true_tail_id}\")\n",
    "\n",
    "# === Summaries ===\n",
    "print(\"\\n--- Personalized Summary Output ---\")\n",
    "print(f\"Generic Summary   : {generic_summary}\")\n",
    "print(f\"Gold Summary   : {gold_summary}\")\n",
    "print(f\"Predicted      : {pred_summary}\")\n",
    "\n",
    "# === Losses ===\n",
    "print(\"\\n--- Loss Breakdown ---\")\n",
    "print(f\"Total Loss     : {loss_total:.4f}\")\n",
    "print(f\"Gen Loss       : {loss_gen:.4f}\")\n",
    "print(f\"Encoder Loss   : {loss_enc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¦ Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 165/500 [00:43<01:08,  4.92it/s, Loss=3.0953, GenLoss=6.1268] "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "lr = 1e-3\n",
    "num_epochs = 100\n",
    "save_every = 10\n",
    "checkpoint_template = \"b2s_model_epoch{:03d}.pt\"\n",
    "resume = True  # set to False if starting fresh\n",
    "start_epoch = 0\n",
    "\n",
    "# === Optimizer ===\n",
    "optimizer = torch.optim.Adam(b2s_model.parameters(), lr=lr)\n",
    "\n",
    "# === Load Checkpoint if Resume Enabled ===\n",
    "if resume:\n",
    "    checkpoint_files = [f for f in os.listdir() if f.startswith(\"b2s_model_epoch\") and f.endswith(\".pt\")]\n",
    "    if checkpoint_files:\n",
    "        last_ckpt = sorted(checkpoint_files)[-1]\n",
    "        ckpt_epoch = int(last_ckpt.split(\"epoch\")[-1].split(\".pt\")[0])\n",
    "        start_epoch = ckpt_epoch\n",
    "        b2s_model.load_state_dict(torch.load(last_ckpt))\n",
    "        print(f\"ðŸ” Loaded checkpoint '{last_ckpt}' and resumed from epoch {start_epoch + 1}\")\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    b2s_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_gen_loss = 0.0\n",
    "\n",
    "    print(f\"\\nðŸŸ¦ Epoch {epoch + 1}/{num_epochs}\")\n",
    "    pbar = tqdm(train_data, desc=f\"Training Epoch {epoch + 1}\", dynamic_ncols=True)\n",
    "\n",
    "    for Bhist, Bpos in pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            (loss_total, loss_txt, loss_enc), pred_summary, gold_summary, generic_summary = b2s_model(\n",
    "                Bhist, Bpos, lookup_df, tail2idx, embed_tables\n",
    "            )\n",
    "        except Exception as e:\n",
    "            pbar.set_postfix_str(f\"[Skip {Bpos}] {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_total.item()\n",
    "        total_gen_loss += loss_txt.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss_total.item():.4f}\",\n",
    "            \"GenLoss\": f\"{loss_txt.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    avg_gen_loss = total_gen_loss / len(train_data)\n",
    "    print(f\"âœ… [Epoch {epoch + 1}] Avg Loss: {avg_loss:.4f} | Gen Loss: {avg_gen_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % save_every == 0:\n",
    "        ckpt_path = checkpoint_template.format(epoch + 1)\n",
    "        torch.save(b2s_model.state_dict(), ckpt_path)\n",
    "        print(f\"ðŸ“Œ Saved checkpoint: {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Re-initialize your model architecture (same as training) ===\n",
    "encoder = BehaviorEncoder().to(device)\n",
    "inverse_mapper = SummaryInverseMapper(hidden_dim).to(device)\n",
    "adapter = CrossAttentionAdapter(query_dim=192, key_value_dim=192, hidden_dim=192).to(device)\n",
    "\n",
    "b2s_model = B2SModel(\n",
    "    encoder=encoder,\n",
    "    inverse_mapper=inverse_mapper,\n",
    "    adapter=adapter,\n",
    "    summarizer_model=summarizer_model,\n",
    "    tokenizer=tokenizer,\n",
    "    nid2body=nid2body,\n",
    "    sid2text=sid2text\n",
    ").to(device)\n",
    "\n",
    "# === Load weights ===\n",
    "checkpoint_path = \"b2s_model_epoch010.pt\"  # <-- change as needed\n",
    "b2s_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "print(f\"âœ… Loaded model checkpoint: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "b2s_model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for Bhist, Bpos in tqdm(test_data, desc=\"ðŸ” Evaluating\"):\n",
    "        try:\n",
    "            loss, pred_summary, gold_summary, generic_summary = b2s_model(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "            true_tail = lookup_df.loc[Bpos, 'Tail']\n",
    "        except Exception as e:\n",
    "            print(f\"[Skip] {Bpos}: {e}\")\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            'Bpos': Bpos,\n",
    "            'true_tail_id': true_tail,\n",
    "            'generic summary':generic_summary,\n",
    "            'pred_summary': pred_summary,\n",
    "            'gold_summary': gold_summary\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "# df.to_csv(\"b2s_eval_results.csv\", index=False)\n",
    "print(\"âœ… Results saved to: b2s_eval_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
