{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PCA 768 → 192 (DICT PICKLES) — END-TO-END SINGLE CELL\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FILES = [\n",
    "    \"/teamspace/studios/this_studio/headline_T5.pkl\",\n",
    "    \"/teamspace/studios/this_studio/newsbody_T5.pkl\",\n",
    "    \"/teamspace/studios/this_studio/summary_T5.pkl\",\n",
    "]\n",
    "\n",
    "TARGET_DIM = 192\n",
    "BATCH_SIZE = 4096\n",
    "PCA_MODEL_PATH = \"/teamspace/studios/this_studio/pca_192_model.pkl\"\n",
    "\n",
    "# ---------------- FIT PCA ----------------\n",
    "ipca = IncrementalPCA(n_components=TARGET_DIM)\n",
    "\n",
    "print(\"\\n[1/3] Fitting PCA (shared across all embeddings)\\n\")\n",
    "\n",
    "for path in FILES:\n",
    "    with open(path, \"rb\") as f:\n",
    "        emb_dict = pickle.load(f)\n",
    "\n",
    "    X = np.stack(list(emb_dict.values())).astype(\"float32\")\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, X.shape[0], BATCH_SIZE),\n",
    "        desc=f\"IPCA fit: {os.path.basename(path)}\"\n",
    "    ):\n",
    "        ipca.partial_fit(X[i:i + BATCH_SIZE])\n",
    "\n",
    "# ---------------- SAVE PCA MODEL ----------------\n",
    "with open(PCA_MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(ipca, f)\n",
    "\n",
    "print(f\"\\nPCA model saved to: {PCA_MODEL_PATH}\")\n",
    "\n",
    "# ---------------- TRANSFORM + SAVE ----------------\n",
    "print(\"\\n[2/3] Applying PCA and saving outputs\\n\")\n",
    "\n",
    "for path in FILES:\n",
    "    with open(path, \"rb\") as f:\n",
    "        emb_dict = pickle.load(f)\n",
    "\n",
    "    keys = list(emb_dict.keys())\n",
    "    X = np.stack([emb_dict[k] for k in keys]).astype(\"float32\")\n",
    "\n",
    "    new_dict = {}\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, X.shape[0], BATCH_SIZE),\n",
    "        desc=f\"PCA transform: {os.path.basename(path)}\"\n",
    "    ):\n",
    "        X_pca = ipca.transform(X[i:i + BATCH_SIZE])\n",
    "        for j, vec in enumerate(X_pca):\n",
    "            new_dict[keys[i + j]] = vec\n",
    "\n",
    "    base, ext = os.path.splitext(path)\n",
    "    out_path = base + \"_pca192\" + ext\n",
    "\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(new_dict, f)\n",
    "\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# ---------------- SANITY CHECK ----------------\n",
    "print(\"\\n[3/3] Sanity check\\n\")\n",
    "\n",
    "with open(FILES[0].replace(\".pkl\", \"_pca192.pkl\"), \"rb\") as f:\n",
    "    test_dict = pickle.load(f)\n",
    "\n",
    "dims = {v.shape[0] for v in test_dict.values()}\n",
    "print(\"Unique embedding dims:\", dims)\n",
    "\n",
    "assert dims == {192}, \"PCA output dimension mismatch\"\n",
    "\n",
    "print(\"\\n✅ PCA pipeline completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1 — Imports\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# ============================================================\n",
    "# CELL 2 — Load T5\n",
    "# ============================================================\n",
    "\n",
    "summarizer_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "summarizer_model.eval()\n",
    "for p in summarizer_model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News loaded: 113762\n",
      "Summaries: 135001\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3 — Load News\n",
    "# ============================================================\n",
    "\n",
    "news_df = pd.read_csv(\"/teamspace/studios/this_studio/news_min (1).tsv\", sep=\"\\t\")\n",
    "nid2body = dict(zip(news_df[\"News ID\"], news_df[\"Headline\"]))\n",
    "\n",
    "print(\"News loaded:\", len(nid2body))\n",
    "# ============================================================\n",
    "# CELL 4 — Load Summary Text\n",
    "# ============================================================\n",
    "\n",
    "with open(\"/teamspace/studios/this_studio/sid2sum.pkl\",\"rb\") as f:\n",
    "    sid2text = pickle.load(f)\n",
    "\n",
    "print(\"Summaries:\", len(sid2text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5 — Device & Dim\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_dim = 192\n",
    "# ============================================================\n",
    "# CELL 6 — Load Embeddings\n",
    "# ============================================================\n",
    "\n",
    "with open(\"/teamspace/studios/this_studio/summary_T5_pca192.pkl\",\"rb\") as f:\n",
    "    summary_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k,v in pickle.load(f).items()}\n",
    "\n",
    "with open(\"/teamspace/studios/this_studio/newsbody_T5_pca192.pkl\",\"rb\") as f:\n",
    "    newsbody_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k,v in pickle.load(f).items()}\n",
    "\n",
    "with open(\"/teamspace/studios/this_studio/headline_T5_pca192.pkl\",\"rb\") as f:\n",
    "    headline_embed = {k: torch.tensor(v, dtype=torch.float32, device=device) for k,v in pickle.load(f).items()}\n",
    "\n",
    "embed_tables = {\n",
    "    \"summary\": summary_embed,\n",
    "    \"newsbody\": newsbody_embed,\n",
    "    \"headline\": headline_embed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7 — Load Behavior Data\n",
    "# ============================================================\n",
    "\n",
    "lookup_df = pd.read_csv(\"/teamspace/studios/this_studio/w2p_engage_list.csv\").set_index(\"EdgeID\")\n",
    "train_df = pd.read_csv(\"/teamspace/studios/this_studio/train_df_gold_only.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1334/38417 [00:00<00:20, 1831.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38417/38417 [00:20<00:00, 1842.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail IDs: 64042\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 8 — Build Tail Vocabulary\n",
    "# ============================================================\n",
    "\n",
    "tail_set = set()\n",
    "for row in tqdm(train_df.itertuples(), total=len(train_df)):\n",
    "    try:\n",
    "        Bhist = literal_eval(row.EHist)\n",
    "        Bpos = row.EPos\n",
    "\n",
    "        for b in Bhist:\n",
    "            if b in lookup_df.index:\n",
    "                tail_set.add(lookup_df.loc[b,\"Tail\"])\n",
    "\n",
    "        if Bpos in lookup_df.index:\n",
    "            tail_set.add(lookup_df.loc[Bpos,\"Tail\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tail_ids = sorted(tail_set)\n",
    "tail2idx = {t:i for i,t in enumerate(tail_ids)}\n",
    "idx2tail = {i:t for t,i in tail2idx.items()}\n",
    "\n",
    "print(\"Tail IDs:\", len(tail2idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9 — Gaussian KDE Kernel\n",
    "# ============================================================\n",
    "\n",
    "LAMBDA = 0.6\n",
    "\n",
    "def gaussian_kernel(x):\n",
    "    return torch.exp(-0.5 * (x ** 2))\n",
    "# ============================================================\n",
    "# CELL 10 — KDE-MI (scalar, last history)\n",
    "# ============================================================\n",
    "\n",
    "def KDE_MI_scalar(e_tl, c_hd_hist):\n",
    "    \"\"\"\n",
    "    e_tl: [D]\n",
    "    c_hd_hist: [T, D] \n",
    "    Returns MI\n",
    "    \"\"\"\n",
    "\n",
    "    if c_hd_hist.shape[0] == 0:\n",
    "        return torch.tensor(0.0, device=e_tl.device)\n",
    "\n",
    "    diffs = (e_tl.unsqueeze(0) - c_hd_hist) / LAMBDA        # [T,D]\n",
    "    k_vals = gaussian_kernel(diffs).prod(dim=1)           # product kernel\n",
    "\n",
    "    p_e = k_vals.mean()\n",
    "    p_c = torch.ones_like(p_e)                            # constant for KDE ratio\n",
    "    p_joint = p_e\n",
    "\n",
    "    mi = torch.log((p_joint + 1e-8) / (p_e * p_c + 1e-8))\n",
    "    return mi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 11 — Action Gates\n",
    "# ============================================================\n",
    "\n",
    "class ActionGates(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_clk = nn.Linear(hidden_dim,1)\n",
    "        self.W_skp = nn.Linear(hidden_dim,1)\n",
    "        self.W_fc  = nn.Linear(hidden_dim,1)\n",
    "        self.W_summ = nn.Linear(hidden_dim,1)\n",
    "        self.W_acc = nn.Linear(hidden_dim,1)\n",
    "\n",
    "    def clk(self, e_tl, dwell):\n",
    "        return (dwell * torch.tanh(self.W_clk(e_tl))).squeeze()\n",
    "\n",
    "    def skp(self, e_tl):\n",
    "        return torch.tanh(self.W_skp(e_tl)).squeeze()\n",
    "\n",
    "    def fc(self, title_emb):\n",
    "        return torch.tanh(self.W_fc(title_emb)).squeeze()\n",
    "\n",
    "    def summ(self, e_tl):\n",
    "        return torch.tanh(self.W_summ(e_tl)).squeeze()\n",
    "\n",
    "    def acc(self, e_hd):\n",
    "        return torch.tanh(self.W_acc(e_hd)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 12 — Memory Kernels\n",
    "# ============================================================\n",
    "\n",
    "class MemoryKernels(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_short = nn.Linear(hidden_dim,1)\n",
    "        self.W_long  = nn.Linear(hidden_dim,1)\n",
    "        self.W_event = nn.Linear(hidden_dim,hidden_dim)\n",
    "\n",
    "    def K_short(self, e):\n",
    "        return torch.exp(-self.W_short(e))\n",
    "\n",
    "    def K_long(self, e):\n",
    "        return torch.exp(-self.W_long(e) / torch.norm(self.W_short.weight))\n",
    "\n",
    "    def K_event(self, e_past, e_now):\n",
    "        return torch.exp(-torch.matmul(self.W_event(e_past), e_now))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 13 — AMF Fusion\n",
    "# ============================================================\n",
    "\n",
    "class AMF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_fuse = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, m_short, m_long, m_event, e_b):\n",
    "        M = torch.stack([m_short, m_long, m_event], dim=0)   # [3,D]\n",
    "        M_soft = torch.softmax(M, dim=0)\n",
    "        m_fuse,_ = torch.max(M_soft, dim=0)\n",
    "\n",
    "        g = torch.tanh(self.W_fuse(e_b))\n",
    "        return g * m_fuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 14 — Paper-Correct BehaviorEncoder\n",
    "# ============================================================\n",
    "\n",
    "class BehaviorEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gates = ActionGates().to(device)\n",
    "        self.kernels = MemoryKernels().to(device)\n",
    "        self.amf = AMF().to(device)\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_dim, device=device))\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, len(tail2idx)).to(device)\n",
    "        self.bpos_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "\n",
    "        enc_loss = torch.tensor(0.0, device=device)\n",
    "        prev_c_hd = torch.zeros(hidden_dim, device=device)\n",
    "        e_b_hist = []\n",
    "        c_hd_hist = []\n",
    "\n",
    "        for t, b_id in enumerate(Bhist):\n",
    "            if b_id not in lookup_df.index:\n",
    "                continue\n",
    "\n",
    "            row = lookup_df.loc[b_id]\n",
    "            head_id, rel, tail_id = row[\"Head\"], row[\"Relation\"], row[\"Tail\"]\n",
    "\n",
    "            e_tl = embed_tables[\"newsbody\"].get(tail_id, torch.zeros(hidden_dim,device=device))\n",
    "            e_hd = prev_c_hd\n",
    "            title_emb = embed_tables[\"headline\"].get(tail_id, torch.zeros(hidden_dim,device=device))\n",
    "\n",
    "            # ---- KDE-MI ----\n",
    "            hist_stack = torch.stack(c_hd_hist[-20:]) if len(c_hd_hist)>0 else torch.zeros((0,hidden_dim),device=device)\n",
    "            I = KDE_MI_scalar(e_tl, hist_stack)\n",
    "\n",
    "            # ---- Action Modulation ----\n",
    "            if rel == \"click\":\n",
    "                dwell = row[\"dwell\"] / lookup_df[\"dwell\"].max()\n",
    "                g = self.gates.clk(e_tl, dwell)\n",
    "                c_hd = g * I\n",
    "\n",
    "            elif rel == \"skip\":\n",
    "                g = self.gates.skp(e_tl)\n",
    "                c_hd = g * e_tl + (1-g) * I\n",
    "\n",
    "            elif rel == \"gen_summ\":\n",
    "                g = self.gates.fc(title_emb)\n",
    "                c_hd = g * I\n",
    "\n",
    "            elif rel == \"summ_gen\":\n",
    "                g1 = self.gates.summ(e_tl)\n",
    "                g2 = self.gates.acc(e_hd)\n",
    "                c_hd = g1 * I + g2 * KDE_MI_scalar(e_tl, torch.stack(e_b_hist[-20:]) if len(e_b_hist)>0 else hist_stack)\n",
    "\n",
    "            else:\n",
    "                c_hd = e_tl\n",
    "\n",
    "            c_hd = self.gamma * c_hd\n",
    "            c_hd_hist.append(c_hd)\n",
    "\n",
    "            # ---- Memory Kernels ----\n",
    "            if len(e_b_hist) > 0:\n",
    "                m_short = sum(self.kernels.K_short(e_b_hist[j]) * e_b_hist[j] for j in range(len(e_b_hist)))\n",
    "                m_long  = sum(self.kernels.K_long(e_b_hist[j])  * e_b_hist[j] for j in range(len(e_b_hist)))\n",
    "                m_event = sum(self.kernels.K_event(e_b_hist[j], c_hd) * e_b_hist[j] for j in range(len(e_b_hist)))\n",
    "            else:\n",
    "                m_short = m_long = m_event = torch.zeros(hidden_dim,device=device)\n",
    "\n",
    "            # ---- AMF ----\n",
    "            m_fuse = self.amf(m_short, m_long, m_event, c_hd)\n",
    "\n",
    "            z_b = c_hd + m_fuse\n",
    "            e_b_hist.append(z_b)\n",
    "            prev_c_hd = c_hd\n",
    "\n",
    "            if tail_id in tail2idx:\n",
    "                logits = self.classifier(z_b.unsqueeze(0))\n",
    "                target = torch.tensor([tail2idx[tail_id]], device=device)\n",
    "                enc_loss += F.cross_entropy(logits, target)\n",
    "\n",
    "        # ---- Next-Step Prediction ----\n",
    "        z_last = e_b_hist[-1]\n",
    "        e_b_pos_pred = self.bpos_mlp(z_last)\n",
    "\n",
    "        b_next = lookup_df.loc[Bpos]\n",
    "        tpos = b_next[\"Tail\"]\n",
    "        logits = self.classifier(e_b_pos_pred.unsqueeze(0))\n",
    "        target = torch.tensor([tail2idx[tpos]], device=device)\n",
    "        pred_loss = F.cross_entropy(logits, target)\n",
    "\n",
    "        total_loss = (0.5*enc_loss + 0.5*pred_loss)/(100*len(Bhist)+1)\n",
    "\n",
    "        return z_last, e_b_pos_pred, total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 15 — Pseudo-Inverse s-Node Extractor\n",
    "# ============================================================\n",
    "\n",
    "class PseudoInverseMapper(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.Wk = nn.Linear(hidden_dim, hidden_dim, bias=False)     # W_k^+\n",
    "        self.Ws = nn.Linear(hidden_dim, hidden_dim, bias=False)     # W_summ^+\n",
    "\n",
    "    def forward(self, z_b):\n",
    "        e_b_hat = self.Wk(z_b)\n",
    "        e_s_hat = self.Ws(e_b_hat)\n",
    "        return e_s_hat\n",
    "# ============================================================\n",
    "# CELL 16 — Cross-Attention (Eq. 19)\n",
    "# ============================================================\n",
    "\n",
    "class CrossAttentionEq19(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wk = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wv = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, e_s, e_d):\n",
    "        Q = self.Wq(e_s).unsqueeze(0)   # [1,D]\n",
    "        K = self.Wk(e_d).unsqueeze(0)   # [1,D]\n",
    "        V = self.Wv(e_d).unsqueeze(0)   # [1,D]\n",
    "\n",
    "        score = torch.matmul(Q, K.T) / np.sqrt(Q.shape[-1])\n",
    "        attn = torch.softmax(score, dim=-1)\n",
    "        out = torch.matmul(attn, V)\n",
    "        return out.squeeze(0)\n",
    "# ============================================================\n",
    "# CELL 17 — B2SModel with Paper-Correct Injection\n",
    "# ============================================================\n",
    "\n",
    "class B2SModel(nn.Module):\n",
    "    def __init__(self, encoder, pseudo_inv, cross_attn, summarizer_model, tokenizer, nid2body, sid2text):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pseudo_inv = pseudo_inv\n",
    "        self.cross_attn = cross_attn\n",
    "        self.summarizer = summarizer_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.nid2body = nid2body\n",
    "        self.sid2text = sid2text\n",
    "        self.to_t5 = nn.Linear(hidden_dim, summarizer_model.config.d_model)\n",
    "\n",
    "    def forward(self, Bhist, Bpos, lookup_df, tail2idx, embed_tables):\n",
    "\n",
    "        # ---- Encode Behavior ----\n",
    "        z_b, e_b_pos_pred, loss_enc = self.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "        # ---- Document ----\n",
    "        head_id = lookup_df.loc[Bpos][\"Head\"]\n",
    "        e_doc = embed_tables[\"newsbody\"].get(head_id, torch.zeros(hidden_dim,device=device))\n",
    "        doc_text = self.nid2body.get(head_id,\"\")\n",
    "\n",
    "        # ---- Pseudo-Inverse ----\n",
    "        e_s_hat = self.pseudo_inv(z_b)\n",
    "\n",
    "        # ---- Cross-Attention (Eq.19) ----\n",
    "        e_p_summ = self.cross_attn(e_s_hat, e_doc)\n",
    "\n",
    "        # ---- T5 Injection ----\n",
    "        adapted = self.to_t5(e_p_summ).unsqueeze(0)\n",
    "\n",
    "        inputs = self.tokenizer(doc_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        enc_out = self.summarizer.encoder(**inputs)\n",
    "\n",
    "        sid = lookup_df.loc[Bpos][\"Tail\"]\n",
    "        gold = self.sid2text.get(sid,\"\")\n",
    "        tgt = self.tokenizer(gold, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "        dec_ids = tgt[\"input_ids\"][:,:-1]\n",
    "        labels = tgt[\"input_ids\"][:,1:]\n",
    "\n",
    "        tok_embed = self.summarizer.get_input_embeddings()(dec_ids)\n",
    "        final_embed = torch.cat([adapted.unsqueeze(1), tok_embed], dim=1)\n",
    "\n",
    "        labels = torch.cat([torch.full((1,1),-100,device=device), labels], dim=1)\n",
    "\n",
    "        out = self.summarizer(\n",
    "            encoder_outputs=enc_out,\n",
    "            decoder_inputs_embeds=final_embed,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        pred = torch.argmax(out.logits, dim=-1)\n",
    "        pred_txt = self.tokenizer.decode(pred[0], skip_special_tokens=True)\n",
    "\n",
    "        total_loss = 0.5*loss_enc + 0.5*out.loss\n",
    "        return (total_loss, out.loss, loss_enc), pred_txt, gold, doc_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 18 — Build Model\n",
    "# ============================================================\n",
    "\n",
    "encoder = BehaviorEncoder().to(device)\n",
    "pseudo_inv = PseudoInverseMapper(hidden_dim).to(device)\n",
    "cross_attn = CrossAttentionEq19(hidden_dim).to(device)\n",
    "\n",
    "b2s_model = B2SModel(\n",
    "    encoder,\n",
    "    pseudo_inv,\n",
    "    cross_attn,\n",
    "    summarizer_model,\n",
    "    tokenizer,\n",
    "    nid2body,\n",
    "    sid2text\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 19 — Train / Test Split\n",
    "# ============================================================\n",
    "\n",
    "train_df_subset = train_df.iloc[:550].reset_index(drop=True)\n",
    "train_rows = train_df_subset.iloc[:500]\n",
    "test_rows  = train_df_subset.iloc[500:550]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     E84\n",
      "1    E133\n",
      "2    E152\n",
      "3    E168\n",
      "4    E230\n",
      "Name: EPos, dtype: object\n",
      "Index(['E1', 'E2', 'E3', 'E4', 'E5'], dtype='object', name='EdgeID')\n"
     ]
    }
   ],
   "source": [
    "print(train_rows[\"EPos\"].head())\n",
    "print(lookup_df.index[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped counts: {'eval': 0, 'lookup': 0, 'tail': 0}\n",
      "Dropped counts: {'eval': 0, 'lookup': 0, 'tail': 0}\n",
      "Train: 500 Test: 50\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def extract_pairs(df):\n",
    "    pairs = []\n",
    "    dropped = {\"eval\": 0, \"lookup\": 0, \"tail\": 0}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # --- EHist ---\n",
    "        Bhist = row[\"EHist\"]\n",
    "        if isinstance(Bhist, str):\n",
    "            try:\n",
    "                Bhist = literal_eval(Bhist)\n",
    "            except Exception:\n",
    "                dropped[\"eval\"] += 1\n",
    "                continue\n",
    "\n",
    "        # --- EPos ---\n",
    "        Bpos = row[\"EPos\"]\n",
    "\n",
    "        # --- lookup ---\n",
    "        if Bpos not in lookup_df.index:\n",
    "            dropped[\"lookup\"] += 1\n",
    "            continue\n",
    "\n",
    "        tail = lookup_df.loc[Bpos, \"Tail\"]\n",
    "\n",
    "        # --- tail vocab ---\n",
    "        if tail not in tail2idx:\n",
    "            dropped[\"tail\"] += 1\n",
    "            continue\n",
    "\n",
    "        pairs.append((Bhist, Bpos))\n",
    "\n",
    "    print(\"Dropped counts:\", dropped)\n",
    "    return pairs\n",
    "train_data = extract_pairs(train_rows)\n",
    "test_data  = extract_pairs(test_rows)\n",
    "\n",
    "print(\"Train:\", len(train_data), \"Test:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  4%|▍         | 19/500 [01:45<52:50,  6.59s/it]"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 20 — Training Loop (with running losses)\n",
    "# ============================================================\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "save_every = 2\n",
    "optimizer = torch.optim.Adam(b2s_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    b2s_model.train()\n",
    "    tot_loss = 0.0\n",
    "    tot_gen  = 0.0\n",
    "    tot_enc  = 0.0\n",
    "    count    = 0\n",
    "\n",
    "    pbar = tqdm(train_data, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for Bhist, Bpos in pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            (loss, gen_loss, enc_loss), _, _, _ = b2s_model(\n",
    "                Bhist, Bpos, lookup_df, tail2idx, embed_tables\n",
    "            )\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot_loss += loss.item()\n",
    "        tot_gen  += gen_loss.item()\n",
    "        tot_enc  += enc_loss.item()\n",
    "        count += 1\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"L_now\": f\"{loss.item():.3f}\",\n",
    "            \"Gen_now\": f\"{gen_loss.item():.3f}\",\n",
    "            \"Enc_now\": f\"{enc_loss.item():.3f}\",\n",
    "            \"L_avg\": f\"{tot_loss/count:.3f}\",\n",
    "            \"Gen_avg\": f\"{tot_gen/count:.3f}\",\n",
    "            \"Enc_avg\": f\"{tot_enc/count:.3f}\"\n",
    "        })\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: \"\n",
    "        f\"AvgTotal={tot_loss/count:.4f} | \"\n",
    "        f\"AvgGen={tot_gen/count:.4f} | \"\n",
    "        f\"AvgEnc={tot_enc/count:.4f}\"\n",
    "    )\n",
    "\n",
    "    if (epoch+1) % save_every == 0:\n",
    "        ckpt = f\"b2s_model_epoch{epoch+1:03d}.pt\"\n",
    "        torch.save(b2s_model.state_dict(), ckpt)\n",
    "        print(\"Saved\", ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 23 — Generator with Latent Injection\n",
    "# ============================================================\n",
    "\n",
    "def generate_personalized_summary(model, Bhist, Bpos, lookup_df, embed_tables, max_len=40):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # ---- Encode Behavior ----\n",
    "        z_b, _, _ = model.encoder(Bhist, Bpos, lookup_df, tail2idx, embed_tables)\n",
    "\n",
    "        # ---- Document ----\n",
    "        head_id = lookup_df.loc[Bpos][\"Head\"]\n",
    "        e_doc = embed_tables[\"newsbody\"].get(head_id, torch.zeros(hidden_dim,device=device))\n",
    "        doc_text = model.nid2body.get(head_id,\"\")\n",
    "\n",
    "        # ---- Pseudo-Inverse ----\n",
    "        e_s_hat = model.pseudo_inv(z_b)\n",
    "\n",
    "        # ---- Cross-Attention (Eq.19) ----\n",
    "        e_p_summ = model.cross_attn(e_s_hat, e_doc)\n",
    "\n",
    "        # ---- Project to T5 ----\n",
    "        latent = model.to_t5(e_p_summ).unsqueeze(0)   # [1,d_model]\n",
    "\n",
    "        # ---- Encode Document ----\n",
    "        enc = model.tokenizer(doc_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        enc_out = model.summarizer.encoder(**enc)\n",
    "\n",
    "        # ---- Create prefix embedding ----\n",
    "        prefix = latent.unsqueeze(1)   # [1,1,d_model]\n",
    "\n",
    "        # ---- Start generation with BOS ----\n",
    "        bos = model.tokenizer.pad_token_id\n",
    "        cur_ids = torch.tensor([[bos]], device=device)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            tok_embed = model.summarizer.get_input_embeddings()(cur_ids)\n",
    "            dec_embed = torch.cat([prefix, tok_embed], dim=1)\n",
    "\n",
    "            out = model.summarizer(\n",
    "                encoder_outputs=enc_out,\n",
    "                decoder_inputs_embeds=dec_embed\n",
    "            )\n",
    "\n",
    "            next_token = torch.argmax(out.logits[:,-1,:], dim=-1)\n",
    "            cur_ids = torch.cat([cur_ids, next_token.unsqueeze(0)], dim=1)\n",
    "\n",
    "            if next_token.item() == model.tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "        return model.tokenizer.decode(cur_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 24 — Use It for Evaluation\n",
    "# ============================================================\n",
    "\n",
    "b2s_model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for Bhist,Bpos in tqdm(test_data, desc=\"Generating\"):\n",
    "        try:\n",
    "            pred = generate_personalized_summary(b2s_model, Bhist, Bpos, lookup_df, embed_tables)\n",
    "            gold = sid2text.get(lookup_df.loc[Bpos,\"Tail\"], \"\")\n",
    "            doc  = nid2body.get(lookup_df.loc[Bpos,\"Head\"], \"\")\n",
    "            true_tail = lookup_df.loc[Bpos,\"Tail\"]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"Bpos\":Bpos,\n",
    "            \"true_tail_id\":true_tail,\n",
    "            \"generic summary\":doc,\n",
    "            \"pred_summary\":pred,\n",
    "            \"gold_summary\":gold\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"b2s_eval_results_autoregressive.csv\", index=False)\n",
    "print(\"Saved b2s_eval_results_autoregressive.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
